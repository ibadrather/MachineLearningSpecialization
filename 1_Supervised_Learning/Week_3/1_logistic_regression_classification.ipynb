{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "It turns out that linear regression is not a good algorithm for classification problems. Let's take a look at why and this will lead us into a different algorithm called logistic regression. Which is one of the most popular and most widely used learning algorithms today.\n",
    "\n",
    "<img src=\"images/c1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "<img src=\"images/c2.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "\n",
    "#### Colclusion: Regression not good for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "<img src=\"images/lr1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "<img src=\"images/lr2.png\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of Logistic Regression Output\n",
    "\n",
    "<img src=\"images/lr3.png\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary\n",
    "\n",
    "<img src=\"images/dc1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "<img src=\"images/dc2.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "### Non-Linear Decision Boundary\n",
    "\n",
    "<img src=\"images/dc3.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "### Non-Linear decision boundaries\n",
    "\n",
    "We can go even more complex in making boundaries. We can take higher order equations too - polynomial features.\n",
    "\n",
    "<img src=\"images/dc4.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/q1.png\" style=\"width:700px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function for logistic regression\n",
    "\n",
    "The cost function gives you a way to measure how well a specific set of parameters fits the training data. Thereby gives you a way to try to choose better parameters.\n",
    "\n",
    "<img src=\"images/cf1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "Recall for linear regression, this is the squared error cost function. The only thing I've changed is that I put the one half inside the summation instead of outside the summation. \n",
    "\n",
    "You might remember that in the case of linear regression, where f(x) is the linear function, w dot x plus b. The cost function looks like this, is a convex function or a bowl shape or hammer shape. Gradient descent will look like this, where you take one step, one step, and so on to converge at the global minimum. \n",
    "\n",
    "Now you could try to use the same cost function for logistic regression. But it turns out that if I were to write f(x) =  1 /(1 + exp(-(W.X + b)))  and plot the cost function using this value of f of x, then the cost will look like this. This becomes what's called a non-convex cost function is not convex. What this means is that if you were to try to use gradient descent. There are lots of local minima that you can get sucking. It turns out that for logistic regression, this squared error cost function is not a good choice. Instead, there will be a different cost function that can make the cost function convex again. The gradient descent can be guaranteed to converge to the global minimum.\n",
    "\n",
    "The only thing I've changed is that I put the one half inside the summation instead of outside the summation. This will make the math you see later on this slide a little bit simpler. In order to build a new cost function, one that we'll use for logistic regression. I'm going to change a little bit the definition of the cost function J(w, b). \n",
    "\n",
    "In particular, if you look inside this summation, let's call this term inside the loss on a single training example. I'm going to denote the loss via this capital L and as a function of the prediction of the learning algorithm, f of x as well as of the true label y. The loss given the predictor f of x and the true label y is equal in this case to 1.5 of the squared difference. We'll see shortly that by choosing a different form for this loss function, will be able to keep the overall cost function, which is 1 over n times the sum of these loss functions to be a convex function. \n",
    "\n",
    "<img src=\"images/cf2.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Loss Function\n",
    "\n",
    "Remember, the loss function measures how well you're doing on one training example and is by summing up the losses on all of the training examples that you then get, the cost function, which measures how well you're doing on the entire training set. \n",
    "\n",
    "If you plot log of f, it looks like this curve here, where f here is on the horizontal axis. A plot of a negative of the log of f looks like this, where we just flip the curve along the horizontal axis. Notice that it intersects the horizontal axis at f equals 1 and continues downward from there. Now, f is the output of logistic regression. Thus, f is always between zero and one because the output of logistic regression is always between zero and one. The only part of the function that's relevant is therefore this part over here, corresponding to f between 0 and 1. \n",
    "\n",
    "Let's zoom in and take a closer look at this part of the graph. If the algorithm predicts a probability close to 1 and the true label is 1, then the loss is very small. It's pretty much 0 because you're very close to the right answer. \n",
    "\n",
    "Now continue with the example of the true label y being 1, say everything is a malignant tumor. If the algorithm predicts 0.5, then the loss is at this point here, which is a bit higher but not that high. Whereas in contrast, if the algorithm were to have outputs at 0.1 if it thinks that there is only a 10 percent chance of the tumor being malignant but y really is 1. If really is malignant, then the loss is this much higher value over here. When y is equal to 1, the loss function incentivizes or nurtures, or helps push the algorithm to make more accurate predictions because the loss is lowest, when it predicts values close to 1. .\n",
    "\n",
    "<img src=\"images/lcf1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "On this slide, let's look at the second part of the loss function corresponding to when y is equal to 0. In this case, the **loss = -log(1 - f(x))**. When this function is plotted, it actually looks like this. The range of f is limited to 0 to 1 because logistic regression only outputs values between 0 and 1. \n",
    "\n",
    "If we zoom in, this is what it looks like. In this plot, corresponding to y equals 0, the vertical axis shows the value of the loss for different values of f(x). When f is 0 or very close to 0, the loss is also going to be very small which means that if the true label is 0 and the model's prediction is very close to 0, well, you nearly got it right so the loss is appropriately very close to 0. The larger the value of f(x) gets, the bigger the loss because the prediction is further from the true label 0. In fact, as that prediction approaches 1, the loss actually approaches infinity. \n",
    "\n",
    "Going back to the tumor prediction example just says if the model predicts that the patient's tumor is almost certain to be malignant, say, 99.9 percent chance of malignancy, that turns out to actually not be malignant, so y equals 0 then we penalize the model with a very high loss. In this case of y equals 0, so this is in the case of y equals 1 on the previous slide, the further the prediction f of x is away from the true value of y, the higher the loss. In fact, if f(x) approaches 0, the loss here actually goes really large and in fact approaches infinity. When the true label is 1, the algorithm is strongly incentivized not to predict something too close to 0.\n",
    "\n",
    "<img src=\"images/lcf2.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost\n",
    "\n",
    "It turns out that with this choice of loss function, the overall cost function will be convex and thus you can reliably use gradient descent to take you to the global minimum.\n",
    "\n",
    "<img src=\"images/lcf4.png\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Cost Function for Logistic Regression\n",
    "\n",
    "#### Simplified Loss Function\n",
    "\n",
    "<img src=\"images/slf.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "#### Simplified Cost Function\n",
    "\n",
    "This particular cost function is derived from statistics using a statistical principle called maximum likelihood estimation, which is an idea from statistics on how to efficiently find parameters for different models. This cost function has the nice property that it is convex. \n",
    "\n",
    "<img src=\"images/scf.png\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent for logistic regression\n",
    "\n",
    "#### Training Logistic Regression\n",
    "\n",
    "To fit the parameters of a logistic regression model, we're going to try to find the values of the parameters w and b that minimize the cost function J of w and b, and we'll again apply gradient descent to do this. Let's take a look at how. In this video we'll focus on how to find a good choice of the parameters w and b. After you've done so, if you give the model a new input, x, say a new patients at the hospital with a certain tumor size and age, then these are diagnosis. The model can then make a prediction, or it can try to estimate the probability that the label y is one. \n",
    "\n",
    "<img src=\"images/tlr.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "\n",
    "The average you can use to minimize the cost function is gradient descent. Here again is the cost function. If you want to minimize the cost j as a function of w and b, well, here's the usual gradient descent algorithm, where you repeatedly update each parameter as the 0 value minus Alpha, the learning rate times this derivative term. \n",
    "\n",
    "Let's take a look at the derivative of j with respect to w_j. This term up on top here, where as usual, j goes from one through n, where n is the number of features. If someone were to apply the rules of calculus, you can show that the derivative with respect to w_j of the cost function capital J is equal to this expression over here, is 1 over m times the sum from 1 through m of this error term. That is f minus the label y times x_j. Here are just x I j is the j feature of training example i. No\n",
    "\n",
    "\n",
    "w let's also look at the derivative of j with respect to the parameter b. It turns out to be this expression over here. It's quite similar to the expression above, except that it is not multiplied by this x superscript i subscript j at the end. \n",
    "\n",
    "Just as a reminder, similar to what you saw for linear regression, the way to carry out these updates is to use simultaneous updates, meaning that you first compute the right-hand side for all of these updates and then simultaneously overwrite all the values on the left at the same time.  \n",
    "\n",
    "<img src=\"images/gdlr1.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "#### Gradient Descent\n",
    "Let me take these derivative expressions here and plug them into these terms here. This gives you gradient descent for logistic regression.\n",
    "\n",
    "Now, one funny thing you might be wondering is, that's weird. These two equations look exactly like the average we had come up with previously for linear regression so you might be wondering, is linear regression actually secretly the same as logistic regression? Well, even though these equations look the same, the reason that this is not linear regression is because the definition for the function f of x has changed. \n",
    "\n",
    "In linear regression, f of x is, this is wx plus b. \n",
    "\n",
    "But in logistic regression, f of x is defined to be the sigmoid function applied to wx plus b. \n",
    "\n",
    "Although the algorithm written looked the same for both linear regression and logistic regression, actually they're two very different algorithms because the definition for f of x is not the same. \n",
    "\n",
    "When we talked about gradient descent for linear regression previously, you saw how you can monitor a gradient descent to make sure it converges. You can just apply the same method for logistic regression to make sure it also converges. \n",
    "\n",
    "I've written out these updates as if you're updating the parameters w_j one parameter at a time. Similar to the discussion on vectorized implementations of linear regression, you can also use vectorization to make gradient descent run faster for logistic regression. I won't dive into the details of the vectorized implementation in this video. But you can also learn more about it and see the code in the optional labs. \n",
    "\n",
    "Now you know how to implement gradient descent for logistic regression. You might also remember feature scaling when we were using linear regression. Where you saw how feature scaling, that is scaling all the features to take on similar ranges of values, say between negative 1 and plus 1, how they can help gradient descent to converge faster. \n",
    "\n",
    "Feature scaling applied the same way to scale the different features to take on similar ranges of values can also speed up gradient descent for logistic regression. \n",
    "\n",
    "<img src=\"images/gdlr2.png\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
